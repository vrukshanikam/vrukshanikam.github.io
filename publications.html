<!DOCTYPE HTML>
<!--
	Editorial by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Vruksha</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Main -->
					<div id="main">
						<div class="inner">

							<!-- Header -->
								<header id="header">
									<ul class="actions">
										<li><a href="index.html" class="button big">Home</a></li>
										<li><a href="publications.html" class="button big">Publications</a></li>
										<li><a href="projects.html" class="button big">Projects</a></li>
										<li><a href="experience.html" class="button big">Experience</a></li>
										<li><a href="talks.html" class="button big">Talks</a></li>
										<li><a href="images/cv.pdf" class="button big">Curriculum Vitae</a></li>
										
											
		
									</ul>
									<ul class="icons">
										<li><a href="#" class="icon brands fa-telegram-plane"><span class="label">iitkmail</span></a></li>
										<li><a href="https://github.com/vrukshanikam" class="icon brands fa-github"><span class="label">github</span></a></li>
										<li><a href="https://www.linkedin.com/in/vruksha-nikam-32716a181/" class="icon brands fa-linkedin"><span class="label">linkedin</span></a></li>	
										<li><a href="https://www.quora.com/profile/Vruksha-Nikam" class="icon brands fa-quora"><span class="label">quora</span></a></li>
										
									</ul>
								</header>


							<!-- Content -->
								<section>
									<header class="major">
										<h2>Publications</h2>
									</header>

									<h2>Long Short-Term Memory Implementation Exploiting Passive RRAM Crossbar Array</h2>
									<h4>Honey Nikam, Siddharth Satyam, Shubham Sahay</h4>
									<p>The ever-increasing demand to extract temporal correlations across sequential data and perform context-based learning in this era of big data has led to the development of long short-term memory (LSTM) networks. Furthermore, there is an urgent need to perform these time-series data-dependent applications including speech/video processing and recognition, language modelling and translation, etc. on compact internet-of-things (IoT) edge devices with limited energy. To this end, in this work, for the first time, we propose an extremely area- and energy-efficient LSTM network implementation exploiting the passive resistive random access memory (RRAM) crossbar array. We developed a hardware-aware LSTM network simulation framework and performed an extensive analysis of the proposed LSTM implementation considering the non-ideal hardware artifacts such as spatial (device-to-device) and temporal variations, non-linearity, noise, etc. utilizing an experimentally calibrated comprehensive phenomenological model for passive RRAM crossbar array. Our results indicate that the proposed passive RRAM crossbar-based LSTM network implementation not only outperforms the prior digital and active 1T-1R crossbar-based LSTM implementations by more than three orders of magnitude in terms of area and two orders of magnitude in terms of training energy for identical network accuracy, but also exhibits robustness against spatial and temporal variations and noise, and a faster convergence rate. Our work may provide the incentive for experimental realization of LSTM networks on passive RRAM crossbar arrays.</p>
									<ul class="actions">
										<li><a href="#" class="button">code</a></li>
										<li><a href="https://arxiv.org/pdf/2111.04588.pdf" class="button">arXiv</a></li>
									</ul>
									<hr class="major" />

									<h2>Accelerating Generative Adversarial Networks through Memristor Crossbars</h2>
									<h4>Siddharth Satyam, Honey Nikam, Shubham Sahay</h4>
									<p>There has been immense development in the area of generative algorithms in recent years. Contrary to the discriminative models, which map high dimensional inputs to class labels, generative models have been extensively used in Variational autoencoders (VAEs) and Generative Adversarial Networks (GANs). Extensive studies have been done to improve unsupervised learning and GANs have been one of the most successful algorithms to come up in the domain. With the benefits of providing greater accuracies, GANs have been expensive in terms of energy and speed, due to the vast number of Vector Matrix Multiplications computed on a large weight matrix. To overcome this hurdle, several works have been done on GPU and FPGA based accelerators. However, the Von Neumann bottleneck limits the accuracies and energy efficiency one can achieve and so Neuromorphic computing has been adopted greatly to exceed these limits. In this work, we have proposed an implementation of GANs on passive memristor crossbar arrays. We have performed a fixed amplitude training to update the weights with the crossbar as the backend. We also proposed to use a true random noise for the network. The simulation results show that our implementation has low energy consumption with comparable accuracies to the software counterpart.</p>
									<ul class="actions">
										<li><a href="#" class="button">code</a></li>
										<li><a href="#" class="button">arXiv</a></li>
									</ul>
									
								</section>

						</div>
					</div>

				

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>
